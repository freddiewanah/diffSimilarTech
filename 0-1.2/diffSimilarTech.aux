\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{chen2016explore,chen2016techland}
\citation{bao2017extracting}
\citation{web:mysql1}
\citation{web:mysql2}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A comparative sentence in a post (\#1008671) that is not explicitly for technology comparison \leavevmode {\color  {red}Change the example.}}}{1}{figure.1}}
\newlabel{fig:example}{{1}{1}{A comparative sentence in a post (\#1008671) that is not explicitly for technology comparison \chen {Change the example.}}{figure.1}{}}
\citation{chen2016towards}
\citation{kusner2015word}
\citation{girvan2002community}
\citation{devlin2018bert}
\citation{barua2014developers,chen2016mining,treude2011programmers}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The overview of our approach \leavevmode {\color  {red}There are three main parts and the third one is the summarizing comparative opinions. Within the third parts, there are two steps i.e., labeling data and extracting sentiment.}}}{2}{figure.2}}
\newlabel{fig:overview}{{2}{2}{The overview of our approach \chen {There are three main parts and the third one is the summarizing comparative opinions. Within the third parts, there are two steps i.e., labeling data and extracting sentiment.}}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Mining Similar Technology}{2}{section.2}}
\newlabel{sec:similarTech}{{2}{2}{Mining Similar Technology}{section.2}{}}
\citation{chen2016mining,mikolov2013efficient}
\citation{mikolov2013efficient}
\citation{mikolov2013distributed}
\citation{kazama2007exploiting,chen2016mining}
\citation{bird2004nltk}
\citation{web:nltktag}
\citation{ye2016software}
\newlabel{fig:w2v_skip}{{3(a)}{3}{Subfigure 3(a)}{subfigure.3.1}{}}
\newlabel{sub@fig:w2v_skip}{{(a)}{3}{Subfigure 3(a)\relax }{subfigure.3.1}{}}
\newlabel{fig:w2v_cbow}{{3(b)}{3}{Subfigure 3(b)}{subfigure.3.2}{}}
\newlabel{sub@fig:w2v_cbow}{{(b)}{3}{Subfigure 3(b)\relax }{subfigure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The architecture of the two word embeddings models. The continuous skip-gram model predicts surrounding words given the central word, and the CBOW model predicts the central word based on the context words. Note the differences in arrow direction between the two models. }}{3}{figure.3}}
\newlabel{fig:w2v}{{3}{3}{The architecture of the two word embeddings models. The continuous skip-gram model predicts surrounding words given the central word, and the CBOW model predicts the central word based on the context words. Note the differences in arrow direction between the two models}{figure.3}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Continuous skip-gram model}}}{3}{figure.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Continuous bag-of-words model}}}{3}{figure.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Learning Tag Embeddings}{3}{subsection.2.1}}
\newlabel{sec:w2v}{{2.1}{3}{Learning Tag Embeddings}{subsection.2.1}{}}
\newlabel{equ:condition_skip}{{1}{3}{Learning Tag Embeddings}{equation.2.1}{}}
\newlabel{equ:condition_cbow}{{2}{3}{Learning Tag Embeddings}{equation.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces POS tagging of the definition sentence of the tag \textit  {Matplotlib} \leavevmode {\color  {red}Please change the example}}}{3}{figure.4}}
\newlabel{fig:exampleChunking}{{4}{3}{POS tagging of the definition sentence of the tag \textit {Matplotlib} \chen {Please change the example}}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Mining Categorical Knowledge}{3}{subsection.2.2}}
\newlabel{sec:categoryKG}{{2.2}{3}{Mining Categorical Knowledge}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Building Similar-technology Knowledge Base}{4}{subsection.2.3}}
\newlabel{equ:similarity}{{3}{4}{Building Similar-technology Knowledge Base}{equation.2.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Examples of filtering results by categorical knowledge (in red)}}{4}{table.1}}
\newlabel{tab:filterResult}{{1}{4}{Examples of filtering results by categorical knowledge (in red)}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Mining Comparative Opinions}{4}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Extracting Comparative Sentences}{4}{subsection.3.1}}
\newlabel{sec:comparativeSentence}{{3.1}{4}{Extracting Comparative Sentences}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Preprocessing}{4}{subsubsection.3.1.1}}
\citation{??}
\citation{chen2019sethesaurus}
\citation{kusner2015word}
\citation{ling2007efficient,pele2009fast}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An example of coreference resolution in comparative sentence. \leavevmode {\color  {red}1. Please change the image like \url  {https://nlp.stanford.edu/projects/corefexample.png} 2. Can we find some example sentences with multiple reference to be replaced?}}}{5}{figure.5}}
\newlabel{fig:coreference}{{5}{5}{An example of coreference resolution in comparative sentence. \chen {1. Please change the image like \url {https://nlp.stanford.edu/projects/corefexample.png} 2. Can we find some example sentences with multiple reference to be replaced?}}{figure.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Locating Candidate Sentences}{5}{subsubsection.3.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Selecting Comparative Sentences}{5}{subsubsection.3.1.3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Examples of alias \leavevmode {\color  {red}Give some other examples}}}{5}{table.2}}
\newlabel{tab:alias}{{2}{5}{Examples of alias \chen {Give some other examples}}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Measure Sentence Similarity}{5}{subsection.3.2}}
\newlabel{sec:measuresimilarity}{{3.2}{5}{Measure Sentence Similarity}{subsection.3.2}{}}
\citation{girvan2002community}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \leavevmode {\color  {OliveGreen}Patterns of comparative single sentences} \leavevmode {\color  {red}1. Please change the examples 2. For each pattern, should we have both TECHs appearing in each pattern?}}}{6}{table.3}}
\newlabel{tab:patternSingle}{{3}{6}{\revise {Patterns of comparative single sentences} \chen {1. Please change the examples 2. For each pattern, should we have both TECHs appearing in each pattern?}}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \leavevmode {\color  {OliveGreen}Patterns of comparative contextual sentences} \leavevmode {\color  {red}1. The first two patterns need to be further discussed. 2. Please preserve the original style of the example}}}{6}{table.4}}
\newlabel{tab:patternMultiple}{{4}{6}{\revise {Patterns of comparative contextual sentences} \chen {1. The first two patterns need to be further discussed. 2. Please preserve the original style of the example}}{table.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An illustration of measuring similarity of two comparative sentences \leavevmode {\color  {red}Please change the example.}}}{6}{figure.6}}
\newlabel{fig:wmd}{{6}{6}{An illustration of measuring similarity of two comparative sentences \chen {Please change the example.}}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Clustering Representative Comparison Aspects}{6}{subsection.3.3}}
\citation{devlin2018bert}
\citation{devlin2018bert}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Examples of similar comparative sentences by Word Mover's Distance \leavevmode {\color  {red}Please use the example which can outline the promising part of our WMD model i.e., the cases which cannot be detected by TF-IDF.}}}{7}{table.5}}
\newlabel{tab:wmd}{{5}{7}{Examples of similar comparative sentences by Word Mover's Distance \chen {Please use the example which can outline the promising part of our WMD model i.e., the cases which cannot be detected by TF-IDF.}}{table.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Communities in the graph of comparative sentences \leavevmode {\color  {red}Please update the example}}}{7}{figure.7}}
\newlabel{fig:communities}{{7}{7}{Communities in the graph of comparative sentences \chen {Please update the example}}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Summarizing Overall Opinion}{7}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Creating the manual label}{7}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Constructing the classifier}{7}{subsection.4.2}}
\newlabel{sec:fineTuning}{{4.2}{7}{Constructing the classifier}{subsection.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces The representative keywords for clusters of \textit  {postgresql} and \textit  {mysql}.}}{8}{table.6}}
\newlabel{tab:aspects}{{6}{8}{The representative keywords for clusters of \textit {postgresql} and \textit {mysql}}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Examples of labeled sentences \leavevmode {\color  {red}1) Please replace the first example, and it can be regarded as a wrong case, 2)Please give one example for each case 3) Please use label ``support A'', ``neutral'' as the name.}}}{8}{table.7}}
\newlabel{tab:label}{{7}{8}{Examples of labeled sentences \chen {1) Please replace the first example, and it can be regarded as a wrong case, 2)Please give one example for each case 3) Please use label ``support A'', ``neutral'' as the name.}}{table.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Implementation}{8}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Dataset}{8}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Tool Support}{8}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Visitor Analysis}{8}{subsection.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiment}{8}{section.6}}
\newlabel{sec:experiment}{{6}{8}{Experiment}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Accuracy of Extracting Comparable Technologies}{8}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}The Accuracy of Tag Category}{8}{subsubsection.6.1.1}}
\citation{sparck1972statistical}
\citation{hartigan1979algorithm}
\citation{le2014distributed}
\citation{devlin2018bert}
\citation{devlin2018bert}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}The Importance of Tag Category}{9}{subsubsection.6.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.3}The impact of parameters of word embedding}{9}{subsubsection.6.1.3}}
\newlabel{sec:comparison_w2v}{{6.1.3}{9}{The impact of parameters of word embedding}{subsubsection.6.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Accuracy and coverage of comparative sentences}{9}{subsection.6.2}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces The accuracy of comparative sentences extraction}}{9}{table.8}}
\newlabel{tab:patternAccuracy}{{8}{9}{The accuracy of comparative sentences extraction}{table.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Accuracy of clustering comparative sentences}{9}{subsection.6.3}}
\newlabel{sec:clusterEvaluate}{{6.3}{9}{Accuracy of clustering comparative sentences}{subsection.6.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}Baseline}{9}{subsubsection.6.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2}Ground Truth}{9}{subsubsection.6.3.2}}
\newlabel{sec:clusteringGroundTruth}{{6.3.2}{9}{Ground Truth}{subsubsection.6.3.2}{}}
\citation{hubert1985comparing}
\citation{vinh2010information}
\citation{rosenberg2007v}
\citation{fowlkes1983method}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces \leavevmode {\color  {blue}Ground Truth for evaluating clustering results}}}{10}{table.9}}
\newlabel{tab:groundTruth}{{9}{10}{\wang {Ground Truth for evaluating clustering results}}{table.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.3}Evaluation Metrics}{10}{subsubsection.6.3.3}}
\newlabel{sec:clusteringGroundTruth}{{6.3.3}{10}{Evaluation Metrics}{subsubsection.6.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Clustering performance}}{10}{table.10}}
\newlabel{tab:clusterEvaluation}{{10}{10}{Clustering performance}{table.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.4}Overall Performance}{10}{subsubsection.6.3.4}}
\citation{sparck1972statistical}
\citation{Cortes1995}
\citation{mcmillan2012detecting,thung2012detecting}
\citation{chen2015simapp,linares2016automatically}
\citation{zhang2017detecting}
\citation{teyton2013automatic,chen2016mining,chen2016similartech}
\citation{gu2017deepam,nguyen2017exploring}
\citation{su2016identifying}
\citation{chen2016learning}
\citation{jones2004traffic}
\citation{horton2001multiple}
\citation{adams2006comparison}
\citation{michail1999assessing}
\citation{uddin2017opiner,uddin2017automatic}
\citation{li2017mining}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Accuracy of Opinion Summarization}{11}{subsection.6.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.1}Baselines}{11}{subsubsection.6.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.2}Ground Truth}{11}{subsubsection.6.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.3}Metrics}{11}{subsubsection.6.4.3}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Opinion summarization performance}}{11}{table.11}}
\newlabel{tab:opinionSummarizationPerformance}{{11}{11}{Opinion summarization performance}{table.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.4}Overall Performance}{11}{subsubsection.6.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Related Works}{11}{section.7}}
\citation{web:similarweb}
\citation{web:alternativeto}
\citation{web:similartechgraph}
\bibstyle{IEEEtran}
\bibdata{reference}
\bibcite{chen2016explore}{1}
\bibcite{chen2016techland}{2}
\bibcite{bao2017extracting}{3}
\bibcite{web:mysql1}{4}
\bibcite{web:mysql2}{5}
\bibcite{chen2016towards}{6}
\bibcite{kusner2015word}{7}
\bibcite{girvan2002community}{8}
\bibcite{devlin2018bert}{9}
\bibcite{barua2014developers}{10}
\bibcite{chen2016mining}{11}
\bibcite{treude2011programmers}{12}
\bibcite{mikolov2013efficient}{13}
\bibcite{mikolov2013distributed}{14}
\bibcite{kazama2007exploiting}{15}
\bibcite{bird2004nltk}{16}
\bibcite{web:nltktag}{17}
\bibcite{ye2016software}{18}
\bibcite{chen2019sethesaurus}{19}
\bibcite{ling2007efficient}{20}
\bibcite{pele2009fast}{21}
\bibcite{web:bertblog}{22}
\bibcite{sparck1972statistical}{23}
\bibcite{hartigan1979algorithm}{24}
\bibcite{le2014distributed}{25}
\bibcite{hubert1985comparing}{26}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion and Future Work}{12}{section.8}}
\@writefile{toc}{\contentsline {section}{References}{12}{section*.1}}
\bibcite{vinh2010information}{27}
\bibcite{rosenberg2007v}{28}
\bibcite{fowlkes1983method}{29}
\bibcite{Cortes1995}{30}
\bibcite{mcmillan2012detecting}{31}
\bibcite{thung2012detecting}{32}
\bibcite{chen2015simapp}{33}
\bibcite{linares2016automatically}{34}
\bibcite{zhang2017detecting}{35}
\bibcite{teyton2013automatic}{36}
\bibcite{chen2016similartech}{37}
\bibcite{gu2017deepam}{38}
\bibcite{nguyen2017exploring}{39}
\bibcite{su2016identifying}{40}
\bibcite{chen2016learning}{41}
\bibcite{jones2004traffic}{42}
\bibcite{horton2001multiple}{43}
\bibcite{adams2006comparison}{44}
\bibcite{michail1999assessing}{45}
\bibcite{uddin2017opiner}{46}
\bibcite{uddin2017automatic}{47}
\bibcite{li2017mining}{48}
\bibcite{web:similarweb}{49}
\bibcite{web:alternativeto}{50}
\bibcite{web:similartechgraph}{51}
